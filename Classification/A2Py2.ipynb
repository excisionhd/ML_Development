{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age Estimation CNN (VGG16, VGG-Face Transfer Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import keras\n",
    "import time\n",
    "from keras import backend as K\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import CSVLogger, EarlyStopping, TensorBoard, ModelCheckpoint \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imread, imresize\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_labels = pd.read_csv('train_target.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation Preprocessing (Canceled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data for flow_from_dir\n",
    "from shutil import copyfile\n",
    "data_size = len(image_labels.index)\n",
    "train_size = data_size - (data_size * 0.2)\n",
    "count = 0\n",
    "\n",
    "for index, row in image_labels.iterrows():\n",
    "    name = row['Id']\n",
    "    age = str(row['Age']) \n",
    "    \n",
    "    if count<train_size:\n",
    "        \n",
    "        if os.path.isdir('data/train/' + age):\n",
    "            copyfile('train/'+name, 'data/train/'+age+'/'+name)\n",
    "        else:\n",
    "            os.makedirs('data/train/'+age)\n",
    "            copyfile('train/'+name, 'data/train/'+age+'/'+name)\n",
    "\n",
    "        count = count + 1\n",
    "\n",
    "\n",
    "    else:\n",
    "        if os.path.isdir('data/validation/' + age):\n",
    "            copyfile('train/'+name, 'data/validation/'+age+'/'+name)\n",
    "        else:\n",
    "            os.makedirs('data/validation/'+age)\n",
    "            copyfile('train/'+name, 'data/validation/'+age+'/'+name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Helper Function to Plot Image\n",
    "def plotImage(image):\n",
    "    f, axarr = plt.subplots(1,2)\n",
    "    axarr[0].imshow(image)\n",
    "    axarr[0].grid()\n",
    "    axarr[0].set_title('Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read images and prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "for index, row in image_labels.iterrows():\n",
    "    image = imread('train/' + row[0], mode='RGB')\n",
    "    image = imresize(image, (244,244,3))\n",
    "    X_train.append(np.array(image))\n",
    "    Y_train.append(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.25, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image and Ages\n",
    "num = 1043\n",
    "plotImage(X_train[num])\n",
    "print(argmax(y_train[num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = np.asarray( images )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = np.size(Y_train, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG-Face Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "image_input = Input(shape=(224,224,3))\n",
    "from keras_vggface.vggface import VGGFace\n",
    "vgg_face_model = VGGFace(input_tensor=image_input, model = 'resnet50', include_top = False, weights='vggface', input_shape=((224,224,3)))\n",
    "    \n",
    "vgg_face_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg_face_model.layers[:-31]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LL = vgg_face_model.get_layer('avg_pool').output\n",
    "x = Flatten(name='flatten')(LL)\n",
    "x = Dense(5000,name = 'fc8')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(4096,name = 'fc9')(x)\n",
    "out = Dense(num_classes, activation='softmax',name='classifier')(x)\n",
    "custom_vgg_face_model = Model(vgg_face_model.input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_vgg_face_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=1e-4, decay=1e-3, momentum=0.9)\n",
    "custom_vgg_face_model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=time.time()\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "callback_list = [early_stop]\n",
    "\n",
    "hist = custom_vgg_face_model.fit(X_train, y_train, batch_size=16, validation_data=(X_test, y_test), epochs=75, callbacks = callback_list, verbose=1)\n",
    "#print('Training time: %s' % (t - time.time()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_vgg_face_model.evaluate(img_data, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "model_json = custom_vgg_face_model.to_json()\n",
    "with open(\"vgg_face_trained.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "custom_vgg_face_model.save_weights(\"vgg_face_model_weights.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = custom_vgg_face_model.predict(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 208\n",
    "print(argmax(predictions[index]))\n",
    "print(predictions)\n",
    "plotImage(testing_data[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "json_file = open('vgg_face_trained.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.load_weights(\"vgg_face_model_weights.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = loaded_model.predict(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 4010\n",
    "print(argmax(pred[s]))\n",
    "plotImage(testing_data[s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG-FACE Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_vggface.vggface import VGGFace\n",
    "vgg_face_model_2 = VGGFace(model = 'resnet50',include_top = False, weights='vggface', input_shape=((244,244,3)))\n",
    "\n",
    "for layer in vgg_face_model_2.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "vgg_face_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LL = vgg_face_model_2.get_layer('avg_pool').output\n",
    "x = Flatten(name='flatten')(LL)\n",
    "x = Dense(5000, activation='relu', name='fc6')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(4096, activation='relu', name='fc8')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(4096,name = 'fc9')(x)\n",
    "out = Dense(num_classes, activation='softmax',name='classifier')(x)\n",
    "vgg_face_model_2 = Model(vgg_face_model_2.input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vgg_face_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.0005, decay=1e-3, momentum=0.95)\n",
    "vgg_face_model_2.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=time.time()\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "#ckpt_save = \"ckpt_vgg_2_weights-{epoch:02d}.hdf5\"\n",
    "#checkpoint = ModelCheckpoint(ckpt_save, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "filepath=\"vgg_face_weights_improvment-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "#tensorboard = TensorBoard(log_dir=\".\", histogram_freq=2000, write_graph=True, write_images=False)\n",
    "callback_list = [early_stop, checkpoint]\n",
    "\n",
    "hist = vgg_face_model_2.fit(X_train, y_train, batch_size=16, validation_data=(X_test, y_test), epochs=75, callbacks = callback_list, verbose=1)\n",
    "print('Training time: %s' % (t - time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "del custom_vgg_face_model_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "last_layer = model.get_layer('fc2').output\n",
    "out = Dense(num_classes, activation='softmax', name='predictions')(model.layers[-2].output)\n",
    "custom_vgg_model = Model(image_input, out)\n",
    "custom_vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=time.time()\n",
    "#\tt = now()\n",
    "hist = custom_vgg_model.fit(img_data, Y_train, batch_size=50, epochs=35, verbose=1)\n",
    "print('Training time: %s' % (t - time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "for file2 in glob.glob('test/*.jpg'):\n",
    "    X_test.append(file2)\n",
    "\n",
    "import re\n",
    "X_test_sorted = sorted(X_test, key=lambda x: (int(re.sub('\\D','',x)),x))\n",
    "\n",
    "testing_images = []\n",
    "\n",
    "for im in X_test_sorted:\n",
    "        image2 = imread(im, mode='RGB')\n",
    "        image3 = imresize(image2, (224,224,3))\n",
    "        testing_images.append(np.asarray(image3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testing_data = np.asarray(testing_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = custom_vgg_model.predict(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(argmax(predictions[1619]))\n",
    "print(predictions)\n",
    "plotImage(testing_data[1619])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(argmax(Y_train[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "model_json = custom_vgg_model.to_json()\n",
    "with open(\"model_correct_trained.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"custom_vgg_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testing_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = []\n",
    "ages = []\n",
    "counter = 0\n",
    "for file2 in os.listdir('test'):\n",
    "    file_names.append(os.path.basename(file2))\n",
    "    ages.append(argmax(predictions[counter]))\n",
    "    counter= counter+1\n",
    "    \n",
    "ordered_files = sorted(file_names, key=lambda x: (int(re.sub('\\D','',x)),x))\n",
    "\n",
    "files = pd.DataFrame(ordered_files)  \n",
    "age = pd.DataFrame(ages) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([files, age],axis=1)\n",
    "result.columns = ['Id', 'Expected']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('answers_vgg_face_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(argmax(Y_train[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotImage(testing_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
